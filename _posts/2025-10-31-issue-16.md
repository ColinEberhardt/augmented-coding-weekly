---
layout: post
title: ! 'Issue #16'
author: ceberhardt
published: true
thumbnail: img/16.png
summary: "This issue highlights Claude Skills for Neo4j, a reminder that AI can code but not build software, Google's new vibe-coding feature for rapid prototyping in AI Studio, and Cursor's Composer model release, which offers little transparency."
---

## [Using Claude Skills with Neo4j](https://towardsdatascience.com/using-claude-skills-with-neo4j/)

<small>TOWARDSDATASCIENCE.COM</small>

Anthropic released Skills a couple of weeks ago, providing a new way to extend agent capability. This excellent blog post take a deep dive into this interesting new feature, to improve Claude's ability to query Neo4j databases. The challenge the author was facing is the limited knowledge LLMs have of more recent Neo4j query syntax, resulting in Claude creating inefficient queries

This post introduces the different conceptual levels of information that skills provide, from discovery, detailed instructions to supporting resources and explains how this approach provides efficient context usage. 

Interestingly they used Claude to help build the skill, asking it to research changes in syntax, and updated subquery formats. The rest of the post gives a detailed breakdown of the skill that they created.

As is often the way with LLMs, the process described above feels very 'human'. If you were a developer who wanted to capitalise on the latest query features you would do exactly what the author instructed Claude to do - research. The difference is, human beings have memory, we can retain knowledge, where LLMs cannot. The author describes skills as "file-based building blocks for procedural memory". 


## [AI can code, but it can't build software](https://bytesauna.com/post/coding-vs-software-engineering)

<small>BYTESAUNA.COM</small>

Matias is an experienced consultant who has recently experienced an uptick in queries from founders and CTOs along the lines of "I've vibe-coded an app, can you help me make it production-ready?". This has caused Matias to reflect on what LLMs can and cannot do, and why his services are still needed.

His pithy conclusion is that:

> "AI can code, but it can't build software"

Building software is more than just writing code, it requires architecting, engineering, making numerous decisions and appropriate compromises. 

AI is great at the first part, emitting code with astonishing speed, but it (currently) has little ability when it comes to the engineering side of software development.

## [Introducing vibe coding in Google AI Studio](https://blog.google/technology/developers/introducing-vibe-coding-in-google-ai-studio/)

<small>BLOG.GOOGLE</small>

Google's AI Studio is their recently launched one-stop-shop for all the developer-focussed AI tools and models, including Nano Banana, Gemini and Veo.

This blog post announces a new vibe-coding feature within the AI Studio:

> "This redesigned experience is meant to take you from prompt to working AI app in minutes"

I gave this feature a quick try, using it to build a clone of the [New York Times Connections game](https://www.nytimes.com/games/connections). Using simple prompting I was able to create a fully-functioning clone in just a few minutes.

![Google AI Studio]({{"img/16.png"| absolute_url}})

This tool is very similar to [Bolt](https://bolt.new/), [Lovable](https://lovable.dev/) and [v0](https://v0.app/), tools which I would [categorise as rapid prototyping tools](https://blog.scottlogic.com/2025/04/01/making-sense-of-the-ai-developer-tools-ecosystem.html). 

Their claim of prompt to working app in minutes definitely holds up. But as noted above, if you want a robust, production-ready app, vibe-coding isn't enough.

## [Composer: Building a fast frontier model with RL](https://cursor.com/blog/composer)

<small>CURSOR.COM</small>

Cursor is a VSCode fork with Ai features integrated throughout. It was an early entrant into the AI developer tooling market, and has experienced significant growth ($500 million ARR in 2025, and a valuation of $9.9 billion). 

Cursor allows you to select the underlying frontier model (e.g. GPT5, Sonnet), in much the same way as GitHub Copilot. However, with this announcement they now have their very own foundational model.

Creating their own model gives Cursor a bit of a moat, as they face stiff competition in this rapidly growing market. 

However, this release blog post left me cold, benchmarks which are not public and a handy wavy reference to results from the "Best Frontier Model". There is very little transparency here!