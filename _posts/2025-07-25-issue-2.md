---
layout: post
title: ! 'Issue #2'
author: ceberhardt
published: false
---

## [Coding with LLMs in the summer of 2025](https://antirez.com/news/154)

<small>ANTIREZ.COM</small>

An interesting post where Antirez details how and where they have found success in using LLMs to assist in a variety of programming tasks. They note that the field has advanced considerably:

> One and half years ago [...] I found LLMs to be already useful, but during these 1.5 years, the progresses they made completely changed the game.

I agree with this observation, the capability of these tools has come on in leaps and bounds.

The post is full of good advice on how to get the most of these tools, although interestingly they advise against integrated tools (e.g. GitHub Copilot), instead favouring using the models directly (via web chat), allowing you to be in complete control over both the instructions you provide to the model and the context (i.e. code snippets, documentation). 

This isn't the way I work, I favour GitHub Copilot. However, this is what makes this field so interesting, the wildly different ways in which people are adopting these tools.

## [Rethinking CLI interfaces for AI](https://www.notcheckmark.com/2025/07/rethinking-cli-interfaces-for-ai/)

<small>NOTCHECKMARK.COM</small>

Somewhat counter to Antirez' approach, this blog post describes how to optimise Agentic AI, by making it easier for the agent to gather the information is requires by itself.  

The post makes the point that we should consider "Information Architecture for LLMs", in order to optimise tools for the agents.

## And Finally

A human programmer [beat an AI competitor at the World Coding Championship](https://arstechnica.com/ai/2025/07/exhausted-man-defeats-ai-model-in-world-coding-championship/)(ARSTECHNICA.COM), indicating that we still have the lead ... but only just.
