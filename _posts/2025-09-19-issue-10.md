---
layout: post
title: ! 'Issue #10'
author: ceberhardt
published: false
---

## [How to turn Claude Code into a domain specific coding agent](https://blog.langchain.com/how-to-turn-claude-code-into-a-domain-specific-coding-agent/)

<small>LANGCHAIN.COM</small>

It is a well-known fact that AI tools work best with mainstream languages (Python, JavaScript) and mainstream libraries, simply because there is an abundance of this information in their training dataset. However, many of us are working with libraries that are not that mainstream, or are entirely private to our organisation.

There are various techniques emerging to address this challenge, for example, you can provide API documentation, that describes your library, to the agent via an MCP server. Or, you can provide the agent with project-specific instructions (via a `claude.md` or `agent.md` file). Or, perhaps you can do both?

And this is where things get confusing - there are so many different ways you can use AI tools and agents, something I [touched on last week](https://colineberhardt.github.io/augmented-coding-weekly/issue-9/) with the "Framework Wars" post. However, how are you supposed to know whether one specific technique or framework is better than another? 

![langchain claude code]({{"img/10.png"| absolute_url}})

What I really like about this post from the langchain team is that they took an evidence-based approach, measuring the effectiveness of each technique. In this instance, they concluded that "Claude + MCP + Claude.md" was the most effective approach. But for me, the more important point here is that they proved it.