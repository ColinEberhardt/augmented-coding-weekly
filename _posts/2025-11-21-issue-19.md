---
layout: post
title: ! 'Issue #19'
author: ceberhardt
published: true
thumbnail: img/19.png
summary: Google releases Gemini 3.0 Pro and their own agentic IDE Antigravity, while the industry debates specification-driven development approaches. Plus, running AI agents in continuous loops and Martin Fowler's perspectives on AI's impact on software engineering.
---

## [Trying out Gemini 3 Pro](https://simonwillison.net/2025/Nov/18/gemini-3/)

<small>SIMONWILLISON.NET</small>

Google's Gemini 3.0 was released earlier this week, upgrading the 2.5 model (released in March) to match the leading rival models. The official release cited performance on a wide rang of benchmarks, where Gemini beats both GPT and Sonnet. Notably the [official release mentioned](https://blog.google/products/gemini/gemini-3/#gemini-3-deep-think):

> "Its responses are smart, concise and direct, trading cliché and flattery for genuine insight"

A bit of a dig at Open AI's GPT model which is still rather sycophantic.

Anyhow, I've linked to Simon's blog post rather than the official release, as his benchmark and narrative give a much better feel for this model, which is positive.

## [Google Antigravity](https://antigravity.google/)

<small>ANTIGRAVITY.GOOGLE</small>

Alongside the Gemini 3.0 model release, Google also announced their very own Agentic IDE, Antigravity. This further underscores just how important the developer market has become for the companies developing foundation models.

![antigravity]({{"img/19.png"| absolute_url}})

Antigravity is a VSCode fork (much like Cursor), with computer use and browser automation built in, allowing the coding agent to iterate and UI-automation test. It also includes parallel agents and the ability to create a plan (which you can edit) before executing long-running tasks. 

Unfortunately many of the early-adopters are reporting that they are hitting API limits within a matter of minutes.

## [Building more with GPT-5.1-Codex-Max](https://openai.com/index/gpt-5-1-codex-max/)

<small>OPENAI.COM</small>

And while Google released Gemini 3.0 with some fanfare, OpenAI released yet another model update. Their GPT 5.1 release dropped just over a week ago, this release is an update to their foundational model, which has received further training on agentic tasks across software engineering, maths, research etc...

Long-running reasoning is a key battleground for the frontier AI companies, and it looks like 5.1 Codex Max now has a (slim) lead, across the popular benchmarks.

The model which is currently in the lead on each benchmark is less important than the fact that significant progress is still being made. There is no sign that AI has hit a scaling limit yet.

## [Spec-Driven Development: The Waterfall Strikes Back](https://marmelab.com/blog/2025/11/12/spec-driven-development-waterfall-strikes-back.html)

<small>MARMELAB.COM</small>

Specification-Driven Development (SDD) is a new concept, emerging earlier this year, but it is rapidly gaining traction with the release of [Amazon Kiro](https://kiro.dev/) and [GitHub's Spec Kit](https://github.com/github/spec-kit) in the last month. With this approach you invest significant time in building a comprehensive specification before handing it over to your AI Agent for implementation.

This post argues that SDD tries to remove developers from the software development process, replacing them with (less capable) coding agents and guarding those agents with meticulous planning.

This blog post argues that this approach mirrors the Waterfall development methodology, where you make a significant investment in big up front designs, often finding them to be insufficient when implementation starts, and plans derailing. Whereas agile trades predictability for adaptability, something which can be achieved with agents, by developing in small iterations.

I very much agree - and am currently writing a post with my experiences of trying SDD.

## [Running Claude Code in a loop](https://anandchowdhary.com/blog/2025/running-claude-code-in-a-loop)

<small>ANANDCHOWDRAY.COM</small>

When faced with a dull and repetitive task (writing unit tests), Anand of course turned to AI. However AI agents halt when they consider a task to be complete. What if you want them to pursue a long-term goal, which requires multiple iterations? To achieve this Anand created [Continuous Claude](https://github.com/AnandChowdhary/continuous-claude), a CLI tool that runs a prompt in a loop with persistent context.

This reminds me of BabyAGI and AutoGPT, both from early 2023, which were early attempts at running LLMs in a loop in pursuit of long-term goals.

This feels like something that will become a feature of AI Agents in the future, but for now, enjoy burning those tokens!

## [How AI will change software engineering – with Martin Fowler](https://newsletter.pragmaticengineer.com/p/martin-fowler)

<small>PRAGMATICENGINEER.COM</small>

In the latest issue of The Pragmatic Engineer, Gergely interviews Martin Fowler, a highly experienced and wise engineer. Martin has lived through many significant advances in our industry, from assembler to high-level languages and the creation of the Agile Manifesto, where he was a co-author. 

Martin feels that LLMs, and AI augmented software development, is the biggest transformation he's experienced in his lifetime. But don't mistake this statement for hype - in this interview Martin considers the impacts with wisdom and pragmatism.

They discuss vibe coding, which Martin feels is a great tool for experimentation, but not production use. On specification driven development, he considers this a useful tool for better defining the task an LLM should undertake, but that the code is still an important artifact that needs to be crafted and understood.

Over the course of almost two hours they cover a host of other topics. Well worth a listen.